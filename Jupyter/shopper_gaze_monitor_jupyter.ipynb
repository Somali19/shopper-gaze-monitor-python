{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DEVICE = CPU\n",
    "%env POSEMODEL=/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml\n",
    "%env MODEL=/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/face-detection-adas-0001/FP32/face-detection-adas-0001.xml\n",
    "%env CPU_EXTENSION = /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension_sse4.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shopper Gaze Monitor.\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit person to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import logging as log\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "from inference import Network\n",
    "from threading import Thread\n",
    "from collections import namedtuple\n",
    "\n",
    "# shoppingInfo contains statistics for the shopping information\n",
    "MyStruct = namedtuple(\"shoppingInfo\", \"shopper, looker\")\n",
    "INFO = MyStruct(0, 0)\n",
    "\n",
    "POSE_CHECKED = False\n",
    "\n",
    "# MQTT server environment variables\n",
    "TOPIC = \"shopper_gaze_monitor\"\n",
    "MQTT_HOST = \"localhost\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_KEEPALIVE_INTERVAL = 60\n",
    "\n",
    "# Global variables\n",
    "TARGET_DEVICE = 'CPU'\n",
    "accepted_devices = ['CPU', 'GPU', 'MYRIAD', 'HETERO:FPGA,CPU', 'HDDL']\n",
    "is_async_mode = True\n",
    "CONFIG_FILE = '../resources/config.json'\n",
    "\n",
    "# Flag to control background thread\n",
    "KEEP_RUNNING = True\n",
    "\n",
    "DELAY = 5\n",
    "\n",
    "\n",
    "def face_detection(res, initial_wh):\n",
    "    \"\"\"\n",
    "    Parse Face detection output.\n",
    "\n",
    "    :param res: Detection results\n",
    "    :param initial_wh: Initial width and height of the FRAME\n",
    "    :return: Co-ordinates of the detected face\n",
    "    \"\"\"\n",
    "    global INFO\n",
    "    faces = []\n",
    "    INFO = INFO._replace(shopper=0)\n",
    "\n",
    "    for obj in res[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > CONFIDENCE:\n",
    "            if obj[3] < 0:\n",
    "                obj[3] = -obj[3]\n",
    "            if obj[4] < 0:\n",
    "                obj[4] = -obj[4]\n",
    "            xmin = int(obj[3] * initial_wh[0])\n",
    "            ymin = int(obj[4] * initial_wh[1])\n",
    "            xmax = int(obj[5] * initial_wh[0])\n",
    "            ymax = int(obj[6] * initial_wh[1])\n",
    "            faces.append([xmin, ymin, xmax, ymax])\n",
    "            INFO = INFO._replace(shopper=len(faces))\n",
    "    return faces\n",
    "\n",
    "\n",
    "def message_runner():\n",
    "    \"\"\"\n",
    "    Publish worker status to MQTT topic.\n",
    "\n",
    "    Pauses for rate second(s) between updates\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    while KEEP_RUNNING:\n",
    "        payload = json.dumps({\"Shopper\": INFO.shopper, \"Looker\": INFO.looker})\n",
    "        time.sleep(1)\n",
    "        CLIENT.publish(TOPIC, payload=payload)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the output.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global INFO\n",
    "    global DELAY\n",
    "    global CLIENT\n",
    "    global KEEP_RUNNING\n",
    "    global POSE_CHECKED\n",
    "    global CONFIDENCE\n",
    "    global TARGET_DEVICE\n",
    "    global is_async_mode\n",
    "\n",
    "    CLIENT = mqtt.Client()\n",
    "    CLIENT.connect(MQTT_HOST, MQTT_PORT, MQTT_KEEPALIVE_INTERVAL)\n",
    "\n",
    "    model = os.environ[\"MODEL\"]\n",
    "    posemodel = os.environ[\"POSEMODEL\"]\n",
    "\n",
    "    try:\n",
    "        CONFIDENCE = float(os.environ['CONFIDENCE'])\n",
    "    except:\n",
    "        CONFIDENCE = 0.5\n",
    "\n",
    "    if 'DEVICE' in os.environ.keys():\n",
    "        TARGET_DEVICE = os.environ['DEVICE']\n",
    "    if 'MULTI' not in TARGET_DEVICE and TARGET_DEVICE not in accepted_devices:\n",
    "        print(\"Unsupported device: \" + TARGET_DEVICE)\n",
    "        sys.exit(1)\n",
    "    elif 'MULTI' in TARGET_DEVICE:\n",
    "        target_devices = TARGET_DEVICE.split(':')[1].split(',')\n",
    "        for multi_device in target_devices:\n",
    "            if multi_device not in accepted_devices:\n",
    "                print(\"Unsupported device: \" + TARGET_DEVICE)\n",
    "                sys.exit(1)\n",
    "    cpu_extension = os.environ['CPU_EXTENSION'] if 'CPU_EXTENSION' in os.environ.keys() else None\n",
    "\n",
    "    if 'FLAG' in os.environ.keys():\n",
    "        async_mode = os.environ['FLAG']\n",
    "        if async_mode == \"sync\":\n",
    "            is_async_mode = False\n",
    "        else:\n",
    "            is_async_mode = True\n",
    "\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\",\n",
    "                    level=log.INFO, stream=sys.stdout)\n",
    "    logger = log.getLogger()\n",
    "\n",
    "    assert os.path.isfile(CONFIG_FILE), \"{} file doesn't exist\".format(CONFIG_FILE)\n",
    "    config = json.loads(open(CONFIG_FILE).read())\n",
    "\n",
    "    for idx, item in enumerate(config['inputs']):\n",
    "        if item['video'].isdigit():\n",
    "            input_stream = int(item['video'])\n",
    "        else:\n",
    "            input_stream = item['video']\n",
    "\n",
    "    cap = cv2.VideoCapture(input_stream)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"ERROR! Unable to open video source\")\n",
    "        return\n",
    "\n",
    "    if input_stream:\n",
    "        cap.open(input_stream)\n",
    "        # Adjust DELAY to match the number of FPS of the video file\n",
    "        DELAY = 1000 / cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Init inference request IDs\n",
    "    cur_request_id = 0\n",
    "    next_request_id = 1\n",
    "\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    infer_network_pose = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    plugin, (n_fd, c_fd, h_fd, w_fd) = infer_network.load_model(model, TARGET_DEVICE,\n",
    "                                                                1, 1, 2, cpu_extension)\n",
    "    n_hp, c_hp, h_hp, w_hp = infer_network_pose.load_model(posemodel,\n",
    "                                                           TARGET_DEVICE, 1, 3, 2,\n",
    "                                                           cpu_extension, plugin)[1]\n",
    "\n",
    "    message_thread = Thread(target=message_runner)\n",
    "    message_thread.setDaemon(True)\n",
    "    message_thread.start()\n",
    "\n",
    "    if is_async_mode:\n",
    "        print(\"Application running in async mode...\")\n",
    "    else:\n",
    "        print(\"Application running in sync mode...\")\n",
    "    det_time_fd = 0\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "\n",
    "        looking = 0\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            KEEP_RUNNING = False\n",
    "            break\n",
    "\n",
    "        initial_wh = [cap.get(3), cap.get(4)]\n",
    "        in_frame_fd = cv2.resize(frame, (w_fd, h_fd))\n",
    "        # Change data layout from HWC to CHW\n",
    "        in_frame_fd = in_frame_fd.transpose((2, 0, 1))\n",
    "        in_frame_fd = in_frame_fd.reshape((n_fd, c_fd, h_fd, w_fd))\n",
    "\n",
    "        if frame is None:\n",
    "            KEEP_RUNNING = False\n",
    "            log.error(\"ERROR! blank FRAME grabbed\")\n",
    "            break\n",
    "\n",
    "        key_pressed = cv2.waitKey(int(DELAY))\n",
    "\n",
    "        # Start asynchronous inference for specified request\n",
    "        inf_start_fd = time.time()\n",
    "        if is_async_mode:\n",
    "            # Async enabled and only one video capture\n",
    "            infer_network.exec_net(next_request_id, in_frame_fd)\n",
    "        else:\n",
    "            # Async disabled\n",
    "            infer_network.exec_net(cur_request_id, in_frame_fd)        # Wait for the result\n",
    "        if infer_network.wait(cur_request_id) == 0:\n",
    "            det_time_fd = time.time() - inf_start_fd\n",
    "\n",
    "            # Results of the output layer of the network\n",
    "            res = infer_network.get_output(cur_request_id)\n",
    "\n",
    "            # Parse face detection output\n",
    "            faces = face_detection(res, initial_wh)\n",
    "\n",
    "            if len(faces) != 0:\n",
    "                # Look for poses\n",
    "                for res_hp in faces:\n",
    "                    xmin, ymin, xmax, ymax = res_hp\n",
    "                    head_pose = frame[ymin:ymax, xmin:xmax]\n",
    "                    in_frame_hp = cv2.resize(head_pose, (w_hp, h_hp))\n",
    "                    in_frame_hp = in_frame_hp.transpose((2, 0, 1))\n",
    "                    in_frame_hp = in_frame_hp.reshape((n_hp, c_hp, h_hp, w_hp))\n",
    "\n",
    "                    inf_start_hp = time.time()\n",
    "                    infer_network_pose.exec_net(0, in_frame_hp)\n",
    "                    infer_network_pose.wait(0)\n",
    "                    det_time_hp = time.time() - inf_start_hp\n",
    "\n",
    "                    # Parse head pose detection results\n",
    "                    angle_p_fc = infer_network_pose.get_output(0, \"angle_p_fc\")\n",
    "                    angle_y_fc = infer_network_pose.get_output(0, \"angle_y_fc\")\n",
    "                    if ((angle_y_fc > -22.5) & (angle_y_fc < 22.5) & (angle_p_fc > -22.5) &\n",
    "                            (angle_p_fc < 22.5)):\n",
    "                        looking += 1\n",
    "                        POSE_CHECKED = True\n",
    "                        INFO = INFO._replace(looker=looking)\n",
    "                    else:\n",
    "                        INFO = INFO._replace(looker=looking)\n",
    "            else:\n",
    "                INFO = INFO._replace(looker=0)\n",
    "\n",
    "        # Draw performance stats\n",
    "        inf_time_message = \"Face Inference time: N\\A for async mode\" if is_async_mode else \\\n",
    "            \"Inference time: {:.3f} ms\".format(det_time_fd * 1000)\n",
    "\n",
    "        if POSE_CHECKED:\n",
    "            head_inf_time_message = \"Head pose Inference time: N\\A for async mode\" if is_async_mode else \\\n",
    "                \"Inference time: {:.3f} ms\".format(det_time_hp * 1000)\n",
    "            cv2.putText(frame, head_inf_time_message, (0, 55),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        log_message = \"Async mode is on.\" if is_async_mode else \\\n",
    "            \"Async mode is off.\"\n",
    "        cv2.putText(frame, log_message, (0, 15), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, inf_time_message, (0, 35), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Shopper: {}\".format(INFO.shopper), (0, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Looker: {}\".format(INFO.looker), (0, 110),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Shopper Gaze Monitor\", frame)\n",
    "\n",
    "        if key_pressed == 27:\n",
    "            print(\"Attempting to stop background threads\")\n",
    "            KEEP_RUNNING = False\n",
    "            break\n",
    "        if key_pressed == 9:\n",
    "            is_async_mode = not is_async_mode\n",
    "            print(\"Switched to {} mode\".format(\"async\" if is_async_mode else \"sync\"))\n",
    "\n",
    "        if is_async_mode:\n",
    "            # Swap infer request IDs\n",
    "            cur_request_id, next_request_id = next_request_id, cur_request_id\n",
    "\n",
    "    infer_network.clean()\n",
    "    infer_network_pose.clean()\n",
    "    message_thread.join()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    CLIENT.disconnect()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
