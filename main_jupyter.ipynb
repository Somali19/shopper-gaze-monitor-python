{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env INPUT_FILE = resources/face-demographics-walking-and-pause.mp4\n",
    "%env POSEMODEL=/opt/intel/openvino/deployment_tools/tools/model_downloader/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001.xml\n",
    "%env MODEL=/opt/intel/openvino/deployment_tools/tools/model_downloader/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001.xml\n",
    "%env CPU_EXTENSION = /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension_sse4.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shopper Gaze Monitor.\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit person to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import logging as log\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "from inference import Network\n",
    "from threading import Thread\n",
    "from collections import namedtuple\n",
    "\n",
    "# shoppingInfo contains statistics for the shopping information\n",
    "MyStruct = namedtuple(\"shoppingInfo\", \"shopper, looker\")\n",
    "INFO = MyStruct(0, 0)\n",
    "\n",
    "POSE_CHECKED = False\n",
    "\n",
    "# MQTT server environment variables\n",
    "TOPIC = \"shopper_gaze_monitor\"\n",
    "MQTT_HOST = \"localhost\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_KEEPALIVE_INTERVAL = 60\n",
    "\n",
    "# Flag to control background thread\n",
    "KEEP_RUNNING = True\n",
    "\n",
    "DELAY = 5\n",
    "\n",
    "\n",
    "def face_detection(res, initial_wh):\n",
    "    \"\"\"\n",
    "    Parse Face detection output.\n",
    "\n",
    "    :param res: Detection results\n",
    "    :param initial_wh: Initial width and height of the FRAME\n",
    "    :return: Co-ordinates of the detected face\n",
    "    \"\"\"\n",
    "    global INFO\n",
    "    faces = []\n",
    "    INFO = INFO._replace(shopper=0)\n",
    "\n",
    "    for obj in res[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > CONFIDENCE:\n",
    "            if obj[3] < 0:\n",
    "                obj[3] = -obj[3]\n",
    "            if obj[4] < 0:\n",
    "                obj[4] = -obj[4]\n",
    "            xmin = int(obj[3] * initial_wh[0])\n",
    "            ymin = int(obj[4] * initial_wh[1])\n",
    "            xmax = int(obj[5] * initial_wh[0])\n",
    "            ymax = int(obj[6] * initial_wh[1])\n",
    "            faces.append([xmin, ymin, xmax, ymax])\n",
    "            INFO = INFO._replace(shopper=len(faces))\n",
    "    return faces\n",
    "\n",
    "\n",
    "def message_runner():\n",
    "    \"\"\"\n",
    "    Publish worker status to MQTT topic.\n",
    "\n",
    "    Pauses for rate second(s) between updates\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    while KEEP_RUNNING:\n",
    "        payload = json.dumps({\"Shopper\": INFO.shopper, \"Looker\": INFO.looker})\n",
    "        time.sleep(1)\n",
    "        CLIENT.publish(TOPIC, payload=payload)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the output.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global INFO\n",
    "    global DELAY\n",
    "    global CLIENT\n",
    "    global KEEP_RUNNING\n",
    "    global POSE_CHECKED\n",
    "    global CONFIDENCE\n",
    "\n",
    "    CLIENT = mqtt.Client()\n",
    "    CLIENT.connect(MQTT_HOST, MQTT_PORT, MQTT_KEEPALIVE_INTERVAL)\n",
    "\n",
    "    input_file = os.environ[\"INPUT_FILE\"]\n",
    "    model = os.environ[\"MODEL\"]\n",
    "    posemodel = os.environ[\"POSEMODEL\"]\n",
    "\n",
    "    try:\n",
    "        CONFIDENCE = float(os.environ['CONFIDENCE'])\n",
    "    except:\n",
    "        CONFIDENCE = 0.5\n",
    "\n",
    "    device = os.environ['DEVICE'] if 'DEVICE' in os.environ.keys() else 'CPU'\n",
    "    cpu_extension = os.environ['CPU_EXTENSION'] if 'CPU_EXTENSION' in os.environ.keys() else None\n",
    "\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\",\n",
    "                    level=log.INFO, stream=sys.stdout)\n",
    "    logger = log.getLogger()\n",
    "\n",
    "    if input_file == 'cam':\n",
    "        input_stream = 0\n",
    "    else:\n",
    "        input_stream = input_file\n",
    "        assert os.path.isfile(input_file), \"Specified input file doesn't exist\"\n",
    "\n",
    "    cap = cv2.VideoCapture(input_stream)\n",
    "\n",
    "    if input_stream:\n",
    "        cap.open(input_stream)\n",
    "        # Adjust DELAY to match the number of FPS of the video file\n",
    "        DELAY = 1000 / cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"ERROR! Unable to open video source\")\n",
    "        return\n",
    "\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    infer_network_pose = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    plugin, (n_fd, c_fd, h_fd, w_fd) = infer_network.load_model(model,\n",
    "                                                      device, 1, 1,\n",
    "                                                      0,\n",
    "                                                      cpu_extension)\n",
    "    n_hp, c_hp, h_hp, w_hp = infer_network_pose.load_model(posemodel,\n",
    "                                                           device, 1, 3,\n",
    "                                                           0,\n",
    "                                                           cpu_extension, plugin)[1]\n",
    "\n",
    "    message_thread = Thread(target=message_runner)\n",
    "    message_thread.setDaemon(True)\n",
    "    message_thread.start()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "\n",
    "        looking = 0\n",
    "        ret, next_frame = cap.read()\n",
    "        if not ret:\n",
    "            KEEP_RUNNING = False\n",
    "            break\n",
    "\n",
    "        initial_wh = [cap.get(3), cap.get(4)]\n",
    "        in_frame_fd = cv2.resize(next_frame, (w_fd, h_fd))\n",
    "        # Change data layout from HWC to CHW\n",
    "        in_frame_fd = in_frame_fd.transpose((2, 0, 1))\n",
    "        in_frame_fd = in_frame_fd.reshape((n_fd, c_fd, h_fd, w_fd))\n",
    "\n",
    "        if next_frame is None:\n",
    "            KEEP_RUNNING = False\n",
    "            log.error(\"ERROR! blank FRAME grabbed\")\n",
    "            break\n",
    "\n",
    "        key_pressed = cv2.waitKey(int(DELAY))\n",
    "\n",
    "        # Start asynchronous inference for specified request\n",
    "        inf_start_fd = time.time()\n",
    "        infer_network.exec_net(0, in_frame_fd)\n",
    "        # Wait for the result\n",
    "        infer_network.wait(0)\n",
    "        det_time_fd = time.time() - inf_start_fd\n",
    "\n",
    "        # Results of the output layer of the network\n",
    "        res = infer_network.get_output(0)\n",
    "\n",
    "        # Parse face detection output\n",
    "        faces = face_detection(res, initial_wh)\n",
    "\n",
    "        if len(faces) != 0:\n",
    "            # Look for poses\n",
    "            for res_hp in faces:\n",
    "                xmin, ymin, xmax, ymax = res_hp\n",
    "                head_pose = frame[ymin:ymax, xmin:xmax]\n",
    "                in_frame_hp = cv2.resize(head_pose, (w_hp, h_hp))\n",
    "                in_frame_hp = in_frame_hp.transpose((2, 0, 1))\n",
    "                in_frame_hp = in_frame_hp.reshape((n_hp, c_hp, h_hp, w_hp))\n",
    "\n",
    "                inf_start_hp = time.time()\n",
    "                infer_network_pose.exec_net(0, in_frame_hp)\n",
    "                infer_network_pose.wait(0)\n",
    "                det_time_hp = time.time() - inf_start_hp\n",
    "\n",
    "\n",
    "                # Parse head pose detection results\n",
    "                angle_p_fc = infer_network_pose.get_output(0, \"angle_p_fc\")\n",
    "                angle_y_fc = infer_network_pose.get_output(0, \"angle_y_fc\")\n",
    "                if ((angle_y_fc > -22.5) & (angle_y_fc < 22.5) & (angle_p_fc > -22.5) &\n",
    "                        (angle_p_fc < 22.5)):\n",
    "                    looking += 1\n",
    "                    POSE_CHECKED = True\n",
    "                    INFO = INFO._replace(looker=looking)\n",
    "                else:\n",
    "                    INFO = INFO._replace(looker=looking)\n",
    "        else:\n",
    "            INFO = INFO._replace(looker=0)\n",
    "\n",
    "        # Draw performance stats\n",
    "        inf_time_message = \"Face Inference time: {:.3f} ms.\".format(\n",
    "            det_time_fd * 1000)\n",
    "\n",
    "        if POSE_CHECKED:\n",
    "            cv2.putText(frame, \"Head pose Inference time: {:.3f} ms.\".format(\n",
    "                det_time_hp * 1000), (0, 35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, inf_time_message, (0, 15), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Shopper: {}\".format(INFO.shopper), (0, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Looker: {}\".format(INFO.looker), (0, 110),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Shopper Gaze Monitor\", frame)\n",
    "\n",
    "        frame = next_frame\n",
    "\n",
    "        if key_pressed == 27:\n",
    "            print(\"Attempting to stop background threads\")\n",
    "            KEEP_RUNNING = False\n",
    "            break\n",
    "\n",
    "    infer_network.clean()\n",
    "    infer_network_pose.clean()\n",
    "    message_thread.join()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    CLIENT.disconnect()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
